{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "071be3f9",
   "metadata": {},
   "source": [
    "# PIMA Indian Diabetes Dataset を使った糖尿病予測 - DNN ハンズオン版\n",
    "\n",
    "このノートブックでは、PIMA Indian Diabetes Datasetを使用して、妊娠経験のある女性の身体測定データから糖尿病の有無を予測する深層学習（DNN）モデルを構築します。従来の機械学習手法との性能比較も行います。\n",
    "\n",
    "## データセットについて\n",
    "- **対象**: ピマ族の妊娠経験のある女性（21歳以上）\n",
    "- **特徴量**: 8つの身体測定値・検査値\n",
    "- **目標変数**: 糖尿病の有無（0: なし、1: あり）\n",
    "- **サンプル数**: 768件\n",
    "\n",
    "## 特徴量の説明\n",
    "1. **Pregnancies**: 妊娠回数\n",
    "2. **Glucose**: 経口ブドウ糖負荷試験での血糖値\n",
    "3. **BloodPressure**: 拡張期血圧（mm Hg）\n",
    "4. **SkinThickness**: 上腕三頭筋の皮膚厚（mm）\n",
    "5. **Insulin**: 2時間後の血清インスリン値（mu U/ml）\n",
    "6. **BMI**: 体格指数（kg/m²）\n",
    "7. **DiabetesPedigreeFunction**: 糖尿病系譜機能\n",
    "8. **Age**: 年齢\n",
    "\n",
    "## 使用する手法\n",
    "- **メイン**: Deep Neural Network (DNN) - TensorFlow/Keras\n",
    "- **比較対象**: ロジスティック回帰、ランダムフォレスト\n",
    "- データ探索・可視化\n",
    "- 前処理（欠損値処理、標準化）\n",
    "- モデル評価・性能分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b63c44d",
   "metadata": {},
   "source": [
    "## 1. 必要なライブラリのインストールとインポート\n",
    "\n",
    "深層学習（DNN）と従来の機械学習に必要なライブラリをインストール・インポートします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911183d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なライブラリをインストール\n",
    "!pip install pandas numpy matplotlib seaborn scikit-learn tensorflow\n",
    "\n",
    "print(\"✅ 全てのライブラリのインストールが完了しました！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9405fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ処理・分析ライブラリ\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 可視化ライブラリ\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Jupyter/Colab用ディスプレイ関数\n",
    "try:\n",
    "    from IPython.display import display\n",
    "except ImportError:\n",
    "    # displayが利用できない場合はprintで代替\n",
    "    def display(x):\n",
    "        print(x)\n",
    "\n",
    "# 機械学習ライブラリ\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "# 深層学習ライブラリ\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# その他\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 日本語フォント設定\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "\n",
    "# グラフの設定\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✅ 全てのライブラリのインポートが完了しました！\")\n",
    "print(f\"pandas version: {pd.__version__}\")\n",
    "print(f\"numpy version: {np.__version__}\")\n",
    "try:\n",
    "    print(f\"scikit-learn version: {sklearn.__version__}\")\n",
    "except AttributeError:\n",
    "    import sklearn\n",
    "    print(f\"scikit-learn version: {sklearn.__version__}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# GPU利用可能性の確認\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"🚀 GPU が利用可能です\")\n",
    "else:\n",
    "    print(\"💻 CPU で実行します\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa55937",
   "metadata": {},
   "source": [
    "## 2. データセットのダウンロードと読み込み\n",
    "\n",
    "PIMA Indian Diabetes Datasetをダウンロードして読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c665c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットのダウンロード\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "\n",
    "# カラム名を定義\n",
    "column_names = [\n",
    "    'Pregnancies',\n",
    "    'Glucose', \n",
    "    'BloodPressure',\n",
    "    'SkinThickness',\n",
    "    'Insulin',\n",
    "    'BMI',\n",
    "    'DiabetesPedigreeFunction',\n",
    "    'Age',\n",
    "    'Outcome'\n",
    "]\n",
    "\n",
    "# データを読み込み\n",
    "print(\"📁 PIMA Indian Diabetes Datasetをダウンロード中...\")\n",
    "df = pd.read_csv(url, names=column_names)\n",
    "\n",
    "print(\"✅ データセットの読み込みが完了しました！\")\n",
    "print(f\"データの形状: {df.shape}\")\n",
    "print(f\"特徴量数: {df.shape[1] - 1}\")\n",
    "print(f\"サンプル数: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c813b2a9",
   "metadata": {},
   "source": [
    "## 3. データの探索と可視化\n",
    "\n",
    "データの基本統計量や分布を確認し、データの特性を理解します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e3467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの最初の5行を表示\n",
    "print(\"📊 データの最初の5行:\")\n",
    "display(df.head())\n",
    "\n",
    "# データの基本情報\n",
    "print(\"\\n📋 データの基本情報:\")\n",
    "print(df.info())\n",
    "\n",
    "# 基本統計量\n",
    "print(\"\\n📈 基本統計量:\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c510f04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目標変数の分布\n",
    "print(\"🎯 糖尿病の有無の分布:\")\n",
    "outcome_counts = df['Outcome'].value_counts()\n",
    "print(f\"糖尿病なし (0): {outcome_counts[0]}人 ({outcome_counts[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"糖尿病あり (1): {outcome_counts[1]}人 ({outcome_counts[1]/len(df)*100:.1f}%)\")\n",
    "\n",
    "# 目標変数の可視化\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# 棒グラフ\n",
    "outcome_counts.plot(kind='bar', ax=axes[0], color=['skyblue', 'lightcoral'])\n",
    "axes[0].set_title('糖尿病の有無の分布')\n",
    "axes[0].set_xlabel('糖尿病')\n",
    "axes[0].set_ylabel('人数')\n",
    "axes[0].set_xticklabels(['なし', 'あり'], rotation=0)\n",
    "\n",
    "# 円グラフ\n",
    "axes[1].pie(outcome_counts.values, labels=['なし', 'あり'], autopct='%1.1f%%', \n",
    "           colors=['skyblue', 'lightcoral'], startangle=90)\n",
    "axes[1].set_title('糖尿病の有無の割合')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5241442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量の分布を可視化\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "feature_columns = df.columns[:-1]  # Outcome以外の列\n",
    "\n",
    "for i, column in enumerate(feature_columns):\n",
    "    # 糖尿病の有無による分布の違いを表示\n",
    "    df[df['Outcome'] == 0][column].hist(alpha=0.7, bins=20, label='糖尿病なし', ax=axes[i], color='skyblue')\n",
    "    df[df['Outcome'] == 1][column].hist(alpha=0.7, bins=20, label='糖尿病あり', ax=axes[i], color='lightcoral')\n",
    "    \n",
    "    axes[i].set_title(f'{column} の分布')\n",
    "    axes[i].set_xlabel(column)\n",
    "    axes[i].set_ylabel('頻度')\n",
    "    axes[i].legend()\n",
    "\n",
    "# 余ったsubplotを非表示\n",
    "axes[8].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a05809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 相関行列の可視化\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, fmt='.2f', cbar_kws={\"shrink\": .8})\n",
    "plt.title('特徴量間の相関行列')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Outcomeとの相関が高い特徴量を表示\n",
    "print(\"🔍 糖尿病の有無(Outcome)との相関:\")\n",
    "correlations = df.corr()['Outcome'].drop('Outcome').sort_values(key=abs, ascending=False)\n",
    "for feature, corr in correlations.items():\n",
    "    print(f\"{feature:25}: {corr:6.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e765f8",
   "metadata": {},
   "source": [
    "## 4. データの前処理\n",
    "\n",
    "欠損値処理、異常値の確認、特徴量スケーリングを行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e65197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値の確認\n",
    "print(\"❓ 欠損値の確認:\")\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "# 0値の確認（生物学的に0になりえない値）\n",
    "print(\"\\n🔍 0値の確認（生物学的に不可能な値）:\")\n",
    "zero_values = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "for column in zero_values:\n",
    "    zero_count = (df[column] == 0).sum()\n",
    "    print(f\"{column:20}: {zero_count:3d}個 ({zero_count/len(df)*100:5.1f}%)\")\n",
    "\n",
    "# データをコピーして前処理\n",
    "df_processed = df.copy()\n",
    "\n",
    "# 0値を中央値で置換（生物学的に0になりえない値のみ）\n",
    "print(\"\\n🔧 0値を中央値で置換中...\")\n",
    "for column in zero_values:\n",
    "    if column in ['SkinThickness', 'Insulin']:  # 特に問題の多い列\n",
    "        # 0以外の値の中央値で置換\n",
    "        median_value = df_processed[df_processed[column] != 0][column].median()\n",
    "        df_processed[column] = df_processed[column].replace(0, median_value)\n",
    "        print(f\"{column}: 0 → {median_value:.1f}\")\n",
    "\n",
    "print(\"✅ 前処理が完了しました！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9e8757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量とターゲットを分離\n",
    "X = df_processed.drop('Outcome', axis=1)\n",
    "y = df_processed['Outcome']\n",
    "\n",
    "print(f\"特徴量の形状: {X.shape}\")\n",
    "print(f\"ターゲットの形状: {y.shape}\")\n",
    "print(f\"特徴量名: {list(X.columns)}\")\n",
    "\n",
    "# 訓練データとテストデータに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\n📊 データ分割結果:\")\n",
    "print(f\"訓練データ: {X_train.shape[0]}件\")\n",
    "print(f\"テストデータ: {X_test.shape[0]}件\")\n",
    "print(f\"訓練データの糖尿病率: {y_train.mean():.3f}\")\n",
    "print(f\"テストデータの糖尿病率: {y_test.mean():.3f}\")\n",
    "\n",
    "# 特徴量の標準化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\n✅ データの分割と標準化が完了しました！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a1002d",
   "metadata": {},
   "source": [
    "## 5. Deep Neural Network (DNN) モデルの構築\n",
    "\n",
    "TensorFlow/Kerasを使用してDNNモデルを構築し、糖尿病予測を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6e47a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN モデルの構築\n",
    "def create_dnn_model(input_dim, hidden_layers=[64, 32, 16], dropout_rate=0.3):\n",
    "    \"\"\"\n",
    "    Deep Neural Network モデルを作成する関数\n",
    "    \n",
    "    Args:\n",
    "        input_dim: 入力次元数\n",
    "        hidden_layers: 隠れ層のニューロン数のリスト\n",
    "        dropout_rate: ドロップアウト率\n",
    "    \n",
    "    Returns:\n",
    "        compiled model\n",
    "    \"\"\"\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # 入力層\n",
    "    model.add(layers.Dense(hidden_layers[0], activation='relu', input_dim=input_dim))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    \n",
    "    # 隠れ層\n",
    "    for units in hidden_layers[1:]:\n",
    "        model.add(layers.Dense(units, activation='relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(dropout_rate))\n",
    "    \n",
    "    # 出力層（二値分類）\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # モデルのコンパイル\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', 'precision', 'recall']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# DNN モデルを作成\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "dnn_model = create_dnn_model(input_dim)\n",
    "\n",
    "print(\"🧠 DNN モデルの構造:\")\n",
    "dnn_model.summary()\n",
    "\n",
    "# コールバック関数の設定\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=20,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=10,\n",
    "        min_lr=0.0001,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"✅ DNN モデルの準備が完了しました！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cde6fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN モデルの学習\n",
    "print(\"🧠 DNN モデルの学習を開始...\")\n",
    "\n",
    "# 検証データの分割（訓練データの20%を使用）\n",
    "X_train_dnn, X_val_dnn, y_train_dnn, y_val_dnn = train_test_split(\n",
    "    X_train_scaled, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "# DNN モデルの学習\n",
    "history = dnn_model.fit(\n",
    "    X_train_dnn, y_train_dnn,\n",
    "    validation_data=(X_val_dnn, y_val_dnn),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# DNN の予測\n",
    "y_pred_dnn = (dnn_model.predict(X_test_scaled) > 0.5).astype(int).flatten()\n",
    "y_pred_proba_dnn = dnn_model.predict(X_test_scaled).flatten()\n",
    "\n",
    "# DNN の性能評価\n",
    "dnn_accuracy = accuracy_score(y_test, y_pred_dnn)\n",
    "dnn_roc_auc = roc_auc_score(y_test, y_pred_proba_dnn)\n",
    "\n",
    "print(f\"\\n🧠 DNN モデルの性能:\")\n",
    "print(f\"テスト精度: {dnn_accuracy:.3f}\")\n",
    "print(f\"ROC AUC: {dnn_roc_auc:.3f}\")\n",
    "\n",
    "# 学習履歴の可視化\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# 精度の履歴\n",
    "axes[0].plot(history.history['accuracy'], label='Training Accuracy')\n",
    "axes[0].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "axes[0].set_title('DNN Model Accuracy')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# 損失の履歴\n",
    "axes[1].plot(history.history['loss'], label='Training Loss')\n",
    "axes[1].plot(history.history['val_loss'], label='Validation Loss')\n",
    "axes[1].set_title('DNN Model Loss')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ DNN モデルの学習が完了しました！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7b6b54",
   "metadata": {},
   "source": [
    "## 6. 従来の機械学習手法との比較\n",
    "\n",
    "DNN と従来の機械学習手法（ロジスティック回帰、ランダムフォレスト）の性能を比較します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2230c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 従来の機械学習モデルを定義（DNN との比較用）\n",
    "comparison_models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "}\n",
    "\n",
    "# 比較モデルの学習と評価\n",
    "comparison_results = {}\n",
    "print(\"📊 従来の機械学習手法で学習を開始...\")\n",
    "\n",
    "for name, model in comparison_models.items():\n",
    "    print(f\"\\n📈 {name} を学習中...\")\n",
    "    \n",
    "    # 交差検証でモデルを評価\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "    \n",
    "    # モデルを学習\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # テストデータで予測\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # 性能指標を計算\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    comparison_results[name] = {\n",
    "        'model': model,\n",
    "        'cv_scores': cv_scores,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'test_accuracy': accuracy,\n",
    "        'roc_auc': roc_auc,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_proba': y_pred_proba\n",
    "    }\n",
    "    \n",
    "    print(f\"交差検証精度: {cv_scores.mean():.3f} (±{cv_scores.std()*2:.3f})\")\n",
    "    print(f\"テスト精度: {accuracy:.3f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "\n",
    "# DNN の結果も追加\n",
    "comparison_results['Deep Neural Network'] = {\n",
    "    'test_accuracy': dnn_accuracy,\n",
    "    'roc_auc': dnn_roc_auc,\n",
    "    'y_pred': y_pred_dnn,\n",
    "    'y_pred_proba': y_pred_proba_dnn\n",
    "}\n",
    "\n",
    "print(\"\\n✅ 全てのモデルの学習が完了しました！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41b7c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル性能の比較表を作成\n",
    "comparison_data = []\n",
    "for name, result in comparison_results.items():\n",
    "    if name == 'Deep Neural Network':\n",
    "        comparison_data.append({\n",
    "            'Model': name,\n",
    "            'Test Accuracy': result['test_accuracy'],\n",
    "            'ROC AUC': result['roc_auc']\n",
    "        })\n",
    "    else:\n",
    "        comparison_data.append({\n",
    "            'Model': name,\n",
    "            'CV Accuracy': result['cv_mean'],\n",
    "            'CV Std': result['cv_std'],\n",
    "            'Test Accuracy': result['test_accuracy'],\n",
    "            'ROC AUC': result['roc_auc']\n",
    "        })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.sort_values('Test Accuracy', ascending=False)\n",
    "\n",
    "print(\"📊 モデル性能比較表:\")\n",
    "display(comparison_df)\n",
    "\n",
    "# 最高性能のモデルを特定\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "best_accuracy = comparison_df.iloc[0]['Test Accuracy']\n",
    "best_roc_auc = comparison_df.iloc[0]['ROC AUC']\n",
    "\n",
    "print(f\"\\n🏆 最高性能モデル: {best_model_name}\")\n",
    "print(f\"テスト精度: {best_accuracy:.3f}\")\n",
    "print(f\"ROC AUC: {best_roc_auc:.3f}\")\n",
    "\n",
    "# ROC曲線の比較\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for name, result in comparison_results.items():\n",
    "    y_pred_proba = result['y_pred_proba']\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = result['roc_auc']\n",
    "    \n",
    "    if name == 'Deep Neural Network':\n",
    "        plt.plot(fpr, tpr, linewidth=3, label=f'{name} (AUC = {roc_auc:.3f})')\n",
    "    else:\n",
    "        plt.plot(fpr, tpr, linewidth=2, label=f'{name} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random (AUC = 0.500)')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves Comparison: DNN vs Traditional ML')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"📈 ROC曲線の比較が完了しました！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86a55c4",
   "metadata": {},
   "source": [
    "## 7. 混同行列と詳細分析\n",
    "\n",
    "各モデルの混同行列を表示し、詳細な性能分析を行います。\n",
    "## 7. 混同行列と詳細分析\n",
    "\n",
    "各モデルの混同行列を表示し、詳細な性能分析を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d9cd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 混同行列の可視化\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "model_names = list(comparison_results.keys())\n",
    "\n",
    "for i, (name, result) in enumerate(comparison_results.items()):\n",
    "    y_pred = result['y_pred']\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['なし', 'あり'], \n",
    "                yticklabels=['なし', 'あり'],\n",
    "                ax=axes[i])\n",
    "    axes[i].set_title(f'{name}\\\\nConfusion Matrix')\n",
    "    axes[i].set_xlabel('Predicted')\n",
    "    axes[i].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 詳細な分類レポート\n",
    "print(\"📋 各モデルの詳細評価:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for name, result in comparison_results.items():\n",
    "    y_pred = result['y_pred']\n",
    "    print(f\"\\\\n🔍 {name}:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(classification_report(y_test, y_pred, target_names=['糖尿病なし', '糖尿病あり']))\n",
    "\n",
    "print(\"✅ 詳細分析が完了しました！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19639df",
   "metadata": {},
   "source": [
    "## 8. まとめと考察\n",
    "\n",
    "### DNN ハンズオンのポイント\n",
    "\n",
    "1. **Deep Neural Network の構築**:\n",
    "   - TensorFlow/Keras を使用した多層ニューラルネットワーク\n",
    "   - Batch Normalization と Dropout による正則化\n",
    "   - Early Stopping による過学習の防止\n",
    "\n",
    "2. **従来手法との比較**:\n",
    "   - ロジスティック回帰: 線形分離手法\n",
    "   - ランダムフォレスト: アンサンブル手法\n",
    "   - DNN: 非線形パターンの学習が可能\n",
    "\n",
    "3. **モデル評価**:\n",
    "   - 精度 (Accuracy)\n",
    "   - ROC AUC: 分類性能の総合指標\n",
    "   - 混同行列: 誤分類パターンの分析\n",
    "\n",
    "### 結果の解釈\n",
    "\n",
    "- **DNN の利点**: 複雑な非線形関係を学習可能\n",
    "- **従来手法の利点**: 解釈しやすさ、学習の安定性\n",
    "- **データサイズ**: 小さなデータセットでは従来手法が有効な場合も\n",
    "\n",
    "### 今後の改善案\n",
    "\n",
    "1. **ハイパーパラメータ調整**: Grid Search, Bayesian Optimization\n",
    "2. **特徴量エンジニアリング**: 新しい特徴量の生成\n",
    "3. **アンサンブル**: 複数モデルの組み合わせ\n",
    "4. **データ拡張**: SMOTE などによる不均衡データ対応\n",
    "\n",
    "このハンズオンを通じて、DNN の基本的な実装方法と従来の機械学習手法との比較方法を学びました。\n",
    "\n",
    "# 混同行列\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "           xticklabels=['糖尿病なし', '糖尿病あり'],\n",
    "           yticklabels=['糖尿病なし', '糖尿病あり'], ax=axes[0])\n",
    "axes[0].set_title(f'{best_model_name}\\n混同行列')\n",
    "axes[0].set_xlabel('予測値')\n",
    "axes[0].set_ylabel('実際値')\n",
    "\n",
    "# ROC曲線\n",
    "fpr, tpr, thresholds = roc_curve(y_test, best_y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, best_y_pred_proba)\n",
    "\n",
    "axes[1].plot(fpr, tpr, color='darkorange', lw=2, \n",
    "            label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "axes[1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
    "axes[1].set_xlim([0.0, 1.0])\n",
    "axes[1].set_ylim([0.0, 1.05])\n",
    "axes[1].set_xlabel('偽陽性率 (False Positive Rate)')\n",
    "axes[1].set_ylabel('真陽性率 (True Positive Rate)')\n",
    "axes[1].set_title(f'{best_model_name}\\nROC曲線')\n",
    "axes[1].legend(loc=\"lower right\")\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7bafdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量重要度の可視化（Random Forestの場合）\n",
    "if best_model_name == 'Random Forest':\n",
    "    # 特徴量重要度を取得\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    # 可視化\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=feature_importance, x='importance', y='feature', palette='viridis')\n",
    "    plt.title(f'{best_model_name} - 特徴量重要度')\n",
    "    plt.xlabel('重要度')\n",
    "    plt.ylabel('特徴量')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"📊 特徴量重要度ランキング:\")\n",
    "    for i, (idx, row) in enumerate(feature_importance.iterrows(), 1):\n",
    "        print(f\"{i:2d}. {row['feature']:25}: {row['importance']:.4f}\")\n",
    "\n",
    "elif best_model_name == 'Logistic Regression':\n",
    "    # 回帰係数を取得\n",
    "    coefficients = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'coefficient': best_model.coef_[0]\n",
    "    })\n",
    "    coefficients['abs_coefficient'] = np.abs(coefficients['coefficient'])\n",
    "    coefficients = coefficients.sort_values('abs_coefficient', ascending=False)\n",
    "    \n",
    "    # 可視化\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    colors = ['red' if x < 0 else 'blue' for x in coefficients['coefficient']]\n",
    "    sns.barplot(data=coefficients, x='coefficient', y='feature', palette=colors)\n",
    "    plt.title(f'{best_model_name} - 回帰係数')\n",
    "    plt.xlabel('回帰係数')\n",
    "    plt.ylabel('特徴量')\n",
    "    plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"📊 回帰係数ランキング（絶対値）:\")\n",
    "    for i, (idx, row) in enumerate(coefficients.iterrows(), 1):\n",
    "        print(f\"{i:2d}. {row['feature']:25}: {row['coefficient']:7.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a1ca6f",
   "metadata": {},
   "source": [
    "## 7. 予測機能の実装とテスト\n",
    "\n",
    "学習したモデルを使って新しいデータに対する予測を行う関数を作成し、実際にテストします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8377de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_diabetes(pregnancies, glucose, blood_pressure, skin_thickness, \n",
    "                    insulin, bmi, diabetes_pedigree, age, model=best_model, scaler=scaler):\n",
    "    \"\"\"\n",
    "    個人の身体測定データから糖尿病のリスクを予測する関数\n",
    "    \n",
    "    Parameters:\n",
    "    - pregnancies: 妊娠回数\n",
    "    - glucose: 血糖値\n",
    "    - blood_pressure: 血圧\n",
    "    - skin_thickness: 皮膚厚\n",
    "    - insulin: インスリン値\n",
    "    - bmi: BMI\n",
    "    - diabetes_pedigree: 糖尿病系譜機能\n",
    "    - age: 年齢\n",
    "    \n",
    "    Returns:\n",
    "    - prediction: 予測結果 (0: 糖尿病なし, 1: 糖尿病あり)\n",
    "    - probability: 糖尿病である確率\n",
    "    \"\"\"\n",
    "    \n",
    "    # 入力データを配列に変換\n",
    "    input_data = np.array([[pregnancies, glucose, blood_pressure, skin_thickness,\n",
    "                           insulin, bmi, diabetes_pedigree, age]])\n",
    "    \n",
    "    # 標準化\n",
    "    input_data_scaled = scaler.transform(input_data)\n",
    "    \n",
    "    # 予測\n",
    "    prediction = model.predict(input_data_scaled)[0]\n",
    "    probability = model.predict_proba(input_data_scaled)[0][1]\n",
    "    \n",
    "    return prediction, probability\n",
    "\n",
    "def interpret_prediction(prediction, probability):\n",
    "    \"\"\"\n",
    "    予測結果を解釈しやすい形で表示する関数\n",
    "    \"\"\"\n",
    "    print(\"🏥 糖尿病予測結果\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    if prediction == 1:\n",
    "        print(f\"⚠️  糖尿病のリスクが高いです\")\n",
    "        print(f\"📊 糖尿病である確率: {probability:.1%}\")\n",
    "        \n",
    "        if probability >= 0.8:\n",
    "            risk_level = \"非常に高い\"\n",
    "        elif probability >= 0.6:\n",
    "            risk_level = \"高い\"\n",
    "        else:\n",
    "            risk_level = \"中程度\"\n",
    "            \n",
    "        print(f\"🚨 リスクレベル: {risk_level}\")\n",
    "        print(\"💡 推奨事項: 医師の診察を受けることをお勧めします\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"✅ 糖尿病のリスクは低いです\")\n",
    "        print(f\"📊 糖尿病である確率: {probability:.1%}\")\n",
    "        print(f\"💡 推奨事項: 健康的な生活習慣を維持しましょう\")\n",
    "\n",
    "print(\"✅ 予測関数の準備が完了しました！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614e07cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストケース1: 糖尿病リスクが高いケース\n",
    "print(\"🧪 テストケース1: 高リスクケース\")\n",
    "print(\"患者情報: 35歳女性、妊娠歴6回、血糖値148、血圧72、皮膚厚35mm、インスリン0、BMI33.6、糖尿病系譜0.627\")\n",
    "\n",
    "prediction1, probability1 = predict_diabetes(\n",
    "    pregnancies=6, glucose=148, blood_pressure=72, skin_thickness=35,\n",
    "    insulin=0, bmi=33.6, diabetes_pedigree=0.627, age=50\n",
    ")\n",
    "\n",
    "interpret_prediction(prediction1, probability1)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# テストケース2: 糖尿病リスクが低いケース\n",
    "print(\"🧪 テストケース2: 低リスクケース\")\n",
    "print(\"患者情報: 25歳女性、妊娠歴1回、血糖値85、血圧66、皮膚厚29mm、インスリン0、BMI26.6、糖尿病系譜0.351\")\n",
    "\n",
    "prediction2, probability2 = predict_diabetes(\n",
    "    pregnancies=1, glucose=85, blood_pressure=66, skin_thickness=29,\n",
    "    insulin=0, bmi=26.6, diabetes_pedigree=0.351, age=31\n",
    ")\n",
    "\n",
    "interpret_prediction(prediction2, probability2)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# テストケース3: 実際のテストデータから1件をランダムに選択\n",
    "import random\n",
    "random_idx = random.randint(0, len(X_test) - 1)\n",
    "actual_outcome = y_test.iloc[random_idx]\n",
    "test_data = X_test.iloc[random_idx]\n",
    "\n",
    "print(f\"🧪 テストケース3: 実際のテストデータ（インデックス: {random_idx}）\")\n",
    "print(f\"実際の結果: {'糖尿病あり' if actual_outcome == 1 else '糖尿病なし'}\")\n",
    "print(f\"患者データ: {dict(test_data)}\")\n",
    "\n",
    "prediction3, probability3 = predict_diabetes(\n",
    "    pregnancies=test_data['Pregnancies'],\n",
    "    glucose=test_data['Glucose'],\n",
    "    blood_pressure=test_data['BloodPressure'],\n",
    "    skin_thickness=test_data['SkinThickness'],\n",
    "    insulin=test_data['Insulin'],\n",
    "    bmi=test_data['BMI'],\n",
    "    diabetes_pedigree=test_data['DiabetesPedigreeFunction'],\n",
    "    age=test_data['Age']\n",
    ")\n",
    "\n",
    "interpret_prediction(prediction3, probability3)\n",
    "\n",
    "# 予測の正確性をチェック\n",
    "if prediction3 == actual_outcome:\n",
    "    print(\"✅ 予測が正解しました！\")\n",
    "else:\n",
    "    print(\"❌ 予測が外れました\")\n",
    "\n",
    "print(f\"予測確率: {probability3:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a776bd",
   "metadata": {},
   "source": [
    "## 8. インタラクティブな予測ツール\n",
    "\n",
    "ユーザーが数値を入力して糖尿病リスクを予測できるインタラクティブなツールを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4c19e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_diabetes_prediction():\n",
    "    \"\"\"\n",
    "    インタラクティブな糖尿病予測ツール\n",
    "    \"\"\"\n",
    "    print(\"🏥 糖尿病リスク予測ツール\")\n",
    "    print(\"=\" * 40)\n",
    "    print(\"以下の項目を入力してください：\\n\")\n",
    "    \n",
    "    try:\n",
    "        # ユーザー入力\n",
    "        pregnancies = int(input(\"妊娠回数: \"))\n",
    "        glucose = float(input(\"血糖値 (mg/dL): \"))\n",
    "        blood_pressure = float(input(\"拡張期血圧 (mmHg): \"))\n",
    "        skin_thickness = float(input(\"上腕三頭筋皮膚厚 (mm): \"))\n",
    "        insulin = float(input(\"2時間後血清インスリン値 (mu U/ml): \"))\n",
    "        bmi = float(input(\"BMI (kg/m²): \"))\n",
    "        diabetes_pedigree = float(input(\"糖尿病系譜機能: \"))\n",
    "        age = int(input(\"年齢: \"))\n",
    "        \n",
    "        print(\"\\n🔄 予測を実行中...\")\n",
    "        \n",
    "        # 予測実行\n",
    "        prediction, probability = predict_diabetes(\n",
    "            pregnancies, glucose, blood_pressure, skin_thickness,\n",
    "            insulin, bmi, diabetes_pedigree, age\n",
    "        )\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        interpret_prediction(prediction, probability)\n",
    "        \n",
    "    except ValueError:\n",
    "        print(\"❌ 正しい数値を入力してください\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ エラーが発生しました: {e}\")\n",
    "\n",
    "# 参考値の表示\n",
    "print(\"📊 参考値：\")\n",
    "print(\"血糖値: 正常値 70-100 mg/dL\")\n",
    "print(\"血圧: 正常値 80-120 mmHg（拡張期）\")\n",
    "print(\"BMI: 正常値 18.5-24.9 kg/m²\")\n",
    "print(\"糖尿病系譜機能: 通常 0.0-2.0程度\")\n",
    "print(\"\\n⚠️ 注意: この予測は参考値であり、医師の診断に代わるものではありません\\n\")\n",
    "\n",
    "# インタラクティブツールの実行（コメントアウト - 必要に応じて有効化）\n",
    "# interactive_diabetes_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f481cb",
   "metadata": {},
   "source": [
    "## 9. モデルの保存と読み込み\n",
    "\n",
    "学習したモデルを保存し、後で再利用できるようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14769a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# モデルとスケーラーを保存\n",
    "print(\"💾 モデルとスケーラーを保存中...\")\n",
    "\n",
    "# 最高性能のモデルを保存\n",
    "model_filename = f'diabetes_model_{best_model_name.lower().replace(\" \", \"_\")}.pkl'\n",
    "scaler_filename = 'diabetes_scaler.pkl'\n",
    "\n",
    "# pickle を使用して保存\n",
    "with open(model_filename, 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "with open(scaler_filename, 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(f\"✅ モデルを保存しました: {model_filename}\")\n",
    "print(f\"✅ スケーラーを保存しました: {scaler_filename}\")\n",
    "\n",
    "# 保存したモデルを読み込んでテスト\n",
    "print(\"\\n📥 保存したモデルを読み込み中...\")\n",
    "\n",
    "with open(model_filename, 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "with open(scaler_filename, 'rb') as f:\n",
    "    loaded_scaler = pickle.load(f)\n",
    "\n",
    "# 読み込んだモデルでテスト予測\n",
    "test_input = X_test.iloc[0:1]\n",
    "test_scaled = loaded_scaler.transform(test_input)\n",
    "loaded_prediction = loaded_model.predict(test_scaled)\n",
    "original_prediction = best_model.predict(scaler.transform(test_input))\n",
    "\n",
    "if loaded_prediction[0] == original_prediction[0]:\n",
    "    print(\"✅ モデルの保存・読み込みが正常に完了しました！\")\n",
    "else:\n",
    "    print(\"❌ モデルの保存・読み込みでエラーが発生しました\")\n",
    "\n",
    "print(f\"元のモデル予測: {original_prediction[0]}\")\n",
    "print(f\"読み込みモデル予測: {loaded_prediction[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00093c90",
   "metadata": {},
   "source": [
    "## 🎯 まとめと結論\n",
    "\n",
    "### 📊 プロジェクト成果\n",
    "\n",
    "1. **データ分析**: PIMA Indian Diabetes Dataset (768サンプル) を詳細に分析\n",
    "2. **前処理**: 欠損値処理、標準化、データ分割を実施\n",
    "3. **モデル比較**: 4つの機械学習アルゴリズムを比較評価\n",
    "4. **予測機能**: 実用的な糖尿病リスク予測システムを構築\n",
    "5. **モデル保存**: 学習済みモデルの永続化を実現\n",
    "\n",
    "### 🏆 最終結果\n",
    "\n",
    "- **最高性能モデル**: {best_model_name}\n",
    "- **テスト精度**: {results[best_model_name]['test_accuracy']:.3f}\n",
    "- **ROC AUC**: {results[best_model_name]['roc_auc']:.3f}\n",
    "\n",
    "### 🔍 重要な特徴量\n",
    "\n",
    "糖尿病予測において特に重要な要因が特定されました。\n",
    "\n",
    "### ⚠️ 注意事項\n",
    "\n",
    "- この予測モデルは**医学的診断ツールではありません**\n",
    "- あくまで**参考情報**として活用してください\n",
    "- 実際の医療判断は**医師の診察**を受けてください\n",
    "- モデルの性能は使用するデータセットに依存します\n",
    "\n",
    "### 💡 今後の改善点\n",
    "\n",
    "1. **より大規模なデータセット**での学習\n",
    "2. **新しい特徴量**の追加（遺伝的要因、生活習慣など）\n",
    "3. **アンサンブル手法**の活用\n",
    "4. **クロスバリデーション**の更なる活用\n",
    "5. **ハイパーパラメータ最適化**の実施\n",
    "\n",
    "### 🔗 参考文献\n",
    "\n",
    "- Smith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261--265). IEEE Computer Society Press.\n",
    "\n",
    "---\n",
    "\n",
    "**🎉 お疲れ様でした！糖尿病予測モデルの構築が完了しました。**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
