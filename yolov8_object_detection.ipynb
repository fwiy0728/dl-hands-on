{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d523093b",
   "metadata": {},
   "source": [
    "# YOLOv8による物体検出 - Google Colab版\n",
    "\n",
    "このノートブックでは、YOLOv8（You Only Look Once v8）を使用して物体検出を行います。YOLOv8は最新の物体検出モデルで、高精度かつ高速な推論が可能です。\n",
    "\n",
    "## 特徴\n",
    "- リアルタイム物体検出\n",
    "- 高精度な位置特定\n",
    "- 80種類のオブジェクトクラスに対応\n",
    "- 画像・動画両方に対応\n",
    "\n",
    "## 必要な環境\n",
    "- Google Colab（推奨）\n",
    "- Python 3.8以上"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8a2ba8",
   "metadata": {},
   "source": [
    "## 1. 必要なライブラリのインストール\n",
    "\n",
    "まず、YOLOv8を使用するために必要なライブラリをインストールします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3111c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv8のメインライブラリであるUltralyticsをインストール\n",
    "!pip install ultralytics\n",
    "\n",
    "# その他の必要なライブラリをインストール（Google Colabには多くが既にインストール済み）\n",
    "!pip install opencv-python-headless pillow matplotlib\n",
    "\n",
    "# インストール完了の確認\n",
    "print(\"✅ 全てのライブラリのインストールが完了しました！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54440419",
   "metadata": {},
   "source": [
    "## 2. ライブラリのインポート\n",
    "\n",
    "物体検出に必要なライブラリをインポートします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf7205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なライブラリをインポート\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from google.colab import files\n",
    "import io\n",
    "\n",
    "# 日本語フォントの設定（可視化用）\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "\n",
    "print(\"✅ 全てのライブラリのインポートが完了しました！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f815292",
   "metadata": {},
   "source": [
    "## 3. YOLOv8モデルの読み込み\n",
    "\n",
    "事前訓練済みのYOLOv8モデルを読み込みます。モデルサイズによって精度と速度が異なります：\n",
    "\n",
    "- **yolov8n**: 最小サイズ（最高速度、最低精度）\n",
    "- **yolov8s**: 小サイズ\n",
    "- **yolov8m**: 中サイズ\n",
    "- **yolov8l**: 大サイズ\n",
    "- **yolov8x**: 最大サイズ（最低速度、最高精度）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e084b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv8モデルを読み込み（初回実行時は自動でダウンロードされます）\n",
    "model = YOLO('yolov8n.pt')  # nanoモデルを使用（高速で軽量）\n",
    "\n",
    "# モデル情報を表示\n",
    "print(\"✅ YOLOv8モデルの読み込みが完了しました！\")\n",
    "print(f\"モデル名: {model.model_name}\")\n",
    "print(f\"クラス数: {len(model.names)}\")\n",
    "print(f\"検出可能なクラス: {list(model.names.values())[:10]}...など\") # 最初の10個を表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45420690",
   "metadata": {},
   "source": [
    "## 4. テスト画像のアップロードと準備\n",
    "\n",
    "Google Colabに画像をアップロードして物体検出を実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9781bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像ファイルをアップロード\n",
    "print(\"📁 画像ファイルを選択してアップロードしてください...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# アップロードされた画像のパスを取得\n",
    "uploaded_image_paths = list(uploaded.keys())\n",
    "print(f\"✅ {len(uploaded_image_paths)}個の画像がアップロードされました\")\n",
    "\n",
    "# アップロードされた画像を表示\n",
    "if uploaded_image_paths:\n",
    "    fig, axes = plt.subplots(1, min(3, len(uploaded_image_paths)), figsize=(15, 5))\n",
    "    if len(uploaded_image_paths) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, image_path in enumerate(uploaded_image_paths[:3]):\n",
    "        img = Image.open(image_path)\n",
    "        if len(uploaded_image_paths) > 1:\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].set_title(f'アップロード画像 {i+1}: {image_path}')\n",
    "            axes[i].axis('off')\n",
    "        else:\n",
    "            axes[0].imshow(img)\n",
    "            axes[0].set_title(f'アップロード画像: {image_path}')\n",
    "            axes[0].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"❌ 画像がアップロードされませんでした\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a79ca38",
   "metadata": {},
   "source": [
    "## 5. 画像での物体検出実行\n",
    "\n",
    "アップロードした画像に対してYOLOv8による物体検出を実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf7515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 物体検出を実行\n",
    "if uploaded_image_paths:\n",
    "    results_list = []\n",
    "    \n",
    "    for image_path in uploaded_image_paths:\n",
    "        print(f\"🔍 {image_path} を解析中...\")\n",
    "        \n",
    "        # YOLOv8で物体検出を実行\n",
    "        results = model(image_path, conf=0.5)  # 信頼度50%以上の検出結果のみ表示\n",
    "        results_list.append(results[0])\n",
    "        \n",
    "        # 検出結果の詳細を表示\n",
    "        print(f\"✅ 検出完了: {len(results[0].boxes)}個のオブジェクトが検出されました\")\n",
    "        \n",
    "        # 検出されたオブジェクトの詳細\n",
    "        if len(results[0].boxes) > 0:\n",
    "            for i, box in enumerate(results[0].boxes):\n",
    "                class_id = int(box.cls[0])\n",
    "                confidence = float(box.conf[0])\n",
    "                class_name = model.names[class_id]\n",
    "                print(f\"  - オブジェクト{i+1}: {class_name} (信頼度: {confidence:.2f})\")\n",
    "        else:\n",
    "            print(\"  - オブジェクトが検出されませんでした\")\n",
    "        print()\n",
    "    \n",
    "    print(\"🎉 全ての画像の物体検出が完了しました！\")\n",
    "else:\n",
    "    print(\"❌ 検出する画像がありません。画像をアップロードしてください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a340df",
   "metadata": {},
   "source": [
    "## 6. 検出結果の可視化\n",
    "\n",
    "検出されたオブジェクトにバウンディングボックス、クラスラベル、信頼度スコアを重ねて表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd14ba05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 検出結果を可視化\n",
    "if uploaded_image_paths and results_list:\n",
    "    \n",
    "    # 画像数に応じてsubplotを調整\n",
    "    num_images = len(uploaded_image_paths)\n",
    "    cols = min(2, num_images)\n",
    "    rows = (num_images + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 8 * rows))\n",
    "    if num_images == 1:\n",
    "        axes = [axes]\n",
    "    elif rows == 1:\n",
    "        axes = [axes] if cols == 1 else axes\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    for i, (image_path, results) in enumerate(zip(uploaded_image_paths, results_list)):\n",
    "        # 画像を読み込み\n",
    "        img = cv2.imread(image_path)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # 検出結果を画像に描画\n",
    "        annotated_img = results.plot()\n",
    "        annotated_img_rgb = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # 表示\n",
    "        if num_images > 1:\n",
    "            axes[i].imshow(annotated_img_rgb)\n",
    "            axes[i].set_title(f'検出結果: {image_path}')\n",
    "            axes[i].axis('off')\n",
    "        else:\n",
    "            axes[0].imshow(annotated_img_rgb)\n",
    "            axes[0].set_title(f'検出結果: {image_path}')\n",
    "            axes[0].axis('off')\n",
    "    \n",
    "    # 余った subplot があれば非表示にする\n",
    "    if num_images < len(axes):\n",
    "        for j in range(num_images, len(axes)):\n",
    "            axes[j].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"🎨 検出結果の可視化が完了しました！\")\n",
    "    print(\"📊 バウンディングボックス内の情報:\")\n",
    "    print(\"   - 色付きの四角: 検出されたオブジェクトの境界\")\n",
    "    print(\"   - テキスト: クラス名と信頼度スコア\")\n",
    "else:\n",
    "    print(\"❌ 表示する結果がありません\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
