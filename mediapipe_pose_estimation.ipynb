{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99a83c6b",
   "metadata": {},
   "source": [
    "# MediaPipe Pose を使ったリアルタイム姿勢推定\n",
    "\n",
    "このノートブックでは、MediaPipe Poseを使用してリアルタイムで人体の姿勢推定を行います。\n",
    "\n",
    "## MediaPipe Poseについて\n",
    "- Googleが開発したオープンソースの機械学習ライブラリ\n",
    "- 高精度かつ高速な姿勢推定が可能\n",
    "- 33個のランドマークポイントを検出\n",
    "- Webカメラやアップロード画像で利用可能"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93ced85",
   "metadata": {},
   "source": [
    "## 1. ライブラリのインストールとインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb62407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なライブラリをインストール\n",
    "!pip install mediapipe opencv-python matplotlib japanize-matplotlib -q\n",
    "\n",
    "print(\"✅ ライブラリのインストールが完了しました！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f56a59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import japanize_matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# MediaPipe Pose の設定\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "print(\"✅ ライブラリのインポートが完了しました！\")\n",
    "print(f\"MediaPipe version: {mp.__version__}\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b06e364",
   "metadata": {},
   "source": [
    "## 2. 画像アップロード機能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd4e100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colabでのファイルアップロード機能\n",
    "try:\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    if uploaded:\n",
    "        # アップロードされたファイルの最初のものを使用\n",
    "        filename = list(uploaded.keys())[0]\n",
    "        print(f\"📁 アップロードされたファイル: {filename}\")\n",
    "    else:\n",
    "        print(\"ファイルがアップロードされませんでした\")\n",
    "        filename = None\n",
    "        \n",
    "except ImportError:\n",
    "    # Google Colab以外の環境の場合はサンプル画像のURLを使用\n",
    "    print(\"🌐 サンプル画像を使用します\")\n",
    "    import urllib.request\n",
    "    \n",
    "    # サンプル画像のダウンロード\n",
    "    sample_url = \"https://images.unsplash.com/photo-1571019613454-1cb2f99b2d8b?w=400\"\n",
    "    filename = \"sample_person.jpg\"\n",
    "    \n",
    "    try:\n",
    "        urllib.request.urlretrieve(sample_url, filename)\n",
    "        print(f\"📁 サンプル画像をダウンロードしました: {filename}\")\n",
    "    except:\n",
    "        print(\"❌ サンプル画像のダウンロードに失敗しました\")\n",
    "        filename = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbf7bbe",
   "metadata": {},
   "source": [
    "## 3. 姿勢推定の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23855059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_pose(image_path):\n",
    "    \"\"\"\n",
    "    画像から姿勢を検出する関数\n",
    "    \"\"\"\n",
    "    # 画像を読み込み\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"❌ 画像を読み込めませんでした: {image_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    # BGR から RGB に変換\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # MediaPipe Pose で姿勢推定\n",
    "    with mp_pose.Pose(\n",
    "        static_image_mode=True,\n",
    "        model_complexity=2,\n",
    "        enable_segmentation=True,\n",
    "        min_detection_confidence=0.5\n",
    "    ) as pose:\n",
    "        \n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        # 結果を描画\n",
    "        annotated_image = image_rgb.copy()\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            landmark_style = mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=5, circle_radius=10)\n",
    "            connection_style = mp_drawing.DrawingSpec(color=(0, 255,), thickness=3)\n",
    "\n",
    "            # ランドマークとスケルトンを描画\n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image,\n",
    "                results.pose_landmarks,\n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=landmark_style,\n",
    "                connection_drawing_spec=connection_style\n",
    "            )\n",
    "            \n",
    "            print(\"✅ 姿勢が検出されました！\")\n",
    "            print(f\"検出されたランドマーク数: {len(results.pose_landmarks.landmark)}\")\n",
    "        else:\n",
    "            print(\"⚠️ 姿勢が検出されませんでした\")\n",
    "    \n",
    "    return image_rgb, annotated_image\n",
    "\n",
    "# 姿勢推定を実行\n",
    "if filename:\n",
    "    original_image, pose_image = detect_pose(filename)\n",
    "    \n",
    "    if original_image is not None and pose_image is not None:\n",
    "        # 結果を表示\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        \n",
    "        # 元の画像\n",
    "        axes[0].imshow(original_image)\n",
    "        axes[0].set_title('元の画像')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # 姿勢推定結果\n",
    "        axes[1].imshow(pose_image)\n",
    "        axes[1].set_title('姿勢推定結果')\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"❌ 処理する画像がありません\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c994a06",
   "metadata": {},
   "source": [
    "## 4. ランドマーク情報の表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c3c7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_landmark_info(image_path):\n",
    "    \"\"\"\n",
    "    ランドマーク情報を詳細に表示する関数\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        return\n",
    "    \n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    with mp_pose.Pose(\n",
    "        static_image_mode=True,\n",
    "        model_complexity=2,\n",
    "        min_detection_confidence=0.5\n",
    "    ) as pose:\n",
    "        \n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            # 主要なランドマークの名前\n",
    "            landmark_names = [\n",
    "                \"鼻\", \"左目（内側）\", \"左目\", \"左目（外側）\", \"右目（内側）\",\n",
    "                \"右目\", \"右目（外側）\", \"左耳\", \"右耳\", \"左口角\",\n",
    "                \"右口角\", \"左肩\", \"右肩\", \"左肘\", \"右肘\",\n",
    "                \"左手首\", \"右手首\", \"左小指\", \"右小指\", \"左人差し指\",\n",
    "                \"右人差し指\", \"左親指\", \"右親指\", \"左腰\", \"右腰\",\n",
    "                \"左膝\", \"右膝\", \"左足首\", \"右足首\", \"左踵\",\n",
    "                \"右踵\", \"左足先\", \"右足先\"\n",
    "            ]\n",
    "            \n",
    "            print(\"🔍 検出されたランドマーク情報:\")\n",
    "            print(\"=\" * 50)\n",
    "            \n",
    "            for i, (landmark, name) in enumerate(zip(results.pose_landmarks.landmark, landmark_names)):\n",
    "                print(f\"{i:2d}. {name:12}: x={landmark.x:.3f}, y={landmark.y:.3f}, z={landmark.z:.3f}, visibility={landmark.visibility:.3f}\")\n",
    "                \n",
    "                # 最初の10個だけ表示（表示を簡潔にするため）\n",
    "                if i >= 9:\n",
    "                    print(\"   ... (残りのランドマークは省略)\")\n",
    "                    break\n",
    "        else:\n",
    "            print(\"❌ ランドマークが検出されませんでした\")\n",
    "\n",
    "# ランドマーク情報を表示\n",
    "if filename:\n",
    "    show_landmark_info(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a48fb9",
   "metadata": {},
   "source": [
    "## 5. まとめ\n",
    "\n",
    "### 🎯 このノートブックで学んだこと\n",
    "\n",
    "1. **MediaPipe Pose の基本的な使い方**\n",
    "   - 簡単なセットアップと設定\n",
    "   - 画像からの姿勢推定\n",
    "\n",
    "2. **姿勢推定の結果**\n",
    "   - 33個のランドマークポイントの検出\n",
    "   - スケルトンの可視化\n",
    "   - 座標情報の取得\n",
    "\n",
    "3. **応用可能性**\n",
    "   - フィットネスアプリ\n",
    "   - 動作解析\n",
    "   - ゲーム制御\n",
    "   - 医療・リハビリ支援\n",
    "\n",
    "### 💡 次のステップ\n",
    "\n",
    "- Webカメラを使ったリアルタイム姿勢推定\n",
    "- 動画ファイルの姿勢推定\n",
    "- 特定の動作やポーズの判定\n",
    "- 複数人の姿勢推定\n",
    "\n",
    "---\n",
    "\n",
    "**🎉 MediaPipe Pose を使った姿勢推定が完了しました！**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835ba149",
   "metadata": {},
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"title-cell\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# MediaPipe Pose を使ったリアルタイム姿勢推定\\n\",\n",
    "    \"\\n\",\n",
    "    \"このノートブックでは、MediaPipe Poseを使用してリアルタイムで人体の姿勢推定を行います。\\n\",\n",
    "    \"\\n\",\n",
    "    \"## MediaPipe Poseについて\\n\",\n",
    "    \"- Googleが開発したオープンソースの機械学習ライブラリ\\n\",\n",
    "    \"- 高精度かつ高速な姿勢推定が可能\\n\",\n",
    "    \"- 33個のランドマークポイントを検出\\n\",\n",
    "    \"- Webカメラやアップロード画像で利用可能\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"section1-title\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. ライブラリのインストールとインポート\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"install-libraries\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# 必要なライブラリをインストール\\n\",\n",
    "    \"!pip install mediapipe opencv-python matplotlib\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"✅ ライブラリのインストールが完了しました！\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"import-libraries\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import cv2\\n\",\n",
    "    \"import mediapipe as mp\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"from PIL import Image\\n\",\n",
    "    \"import io\\n\",\n",
    "    \"import base64\\n\",\n",
    "    \"from IPython.display import display, HTML\\n\",\n",
    "    \"\\n\",\n",
    "    \"# MediaPipe Pose の設定\\n\",\n",
    "    \"mp_pose = mp.solutions.pose\\n\",\n",
    "    \"mp_drawing = mp.solutions.drawing_utils\\n\",\n",
    "    \"mp_drawing_styles = mp.solutions.drawing_styles\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"✅ ライブラリのインポートが完了しました！\\\")\\n\",\n",
    "    \"print(f\\\"MediaPipe version: {mp.__version__}\\\")\\n\",\n",
    "    \"print(f\\\"OpenCV version: {cv2.__version__}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"section2-title\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. 画像アップロード機能\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"upload-image\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Google Colabでのファイルアップロード機能\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    from google.colab import files\\n\",\n",
    "    \"    uploaded = files.upload()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if uploaded:\\n\",\n",
    "    \"        # アップロードされたファイルの最初のものを使用\\n\",\n",
    "    \"        filename = list(uploaded.keys())[0]\\n\",\n",
    "    \"        print(f\\\"📁 アップロードされたファイル: {filename}\\\")\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        print(\\\"ファイルがアップロードされませんでした\\\")\\n\",\n",
    "    \"        filename = None\\n\",\n",
    "    \"        \\n\",\n",
    "    \"except ImportError:\\n\",\n",
    "    \"    # Google Colab以外の環境の場合はサンプル画像のURLを使用\\n\",\n",
    "    \"    print(\\\"🌐 サンプル画像を使用します\\\")\\n\",\n",
    "    \"    import urllib.request\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # サンプル画像のダウンロード\\n\",\n",
    "    \"    sample_url = \\\"https://images.unsplash.com/photo-1571019613454-1cb2f99b2d8b?w=400\\\"\\n\",\n",
    "    \"    filename = \\\"sample_person.jpg\\\"\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        urllib.request.urlretrieve(sample_url, filename)\\n\",\n",
    "    \"        print(f\\\"📁 サンプル画像をダウンロードしました: {filename}\\\")\\n\",\n",
    "    \"    except:\\n\",\n",
    "    \"        print(\\\"❌ サンプル画像のダウンロードに失敗しました\\\")\\n\",\n",
    "    \"        filename = None\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"section3-title\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. 姿勢推定の実行\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"pose-detection\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def detect_pose(image_path):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    画像から姿勢を検出する関数\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    # 画像を読み込み\\n\",\n",
    "    \"    image = cv2.imread(image_path)\\n\",\n",
    "    \"    if image is None:\\n\",\n",
    "    \"        print(f\\\"❌ 画像を読み込めませんでした: {image_path}\\\")\\n\",\n",
    "    \"        return None, None\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # BGR から RGB に変換\\n\",\n",
    "    \"    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # MediaPipe Pose で姿勢推定\\n\",\n",
    "    \"    with mp_pose.Pose(\\n\",\n",
    "    \"        static_image_mode=True,\\n\",\n",
    "    \"        model_complexity=2,\\n\",\n",
    "    \"        enable_segmentation=True,\\n\",\n",
    "    \"        min_detection_confidence=0.5\\n\",\n",
    "    \"    ) as pose:\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        results = pose.process(image_rgb)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # 結果を描画\\n\",\n",
    "    \"        annotated_image = image_rgb.copy()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if results.pose_landmarks:\\n\",\n",
    "    \"            # ランドマークとスケルトンを描画\\n\",\n",
    "    \"            mp_drawing.draw_landmarks(\\n\",\n",
    "    \"                annotated_image,\\n\",\n",
    "    \"                results.pose_landmarks,\\n\",\n",
    "    \"                mp_pose.POSE_CONNECTIONS,\\n\",\n",
    "    \"                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()\\n\",\n",
    "    \"            )\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            print(\\\"✅ 姿勢が検出されました！\\\")\\n\",\n",
    "    \"            print(f\\\"検出されたランドマーク数: {len(results.pose_landmarks.landmark)}\\\")\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            print(\\\"⚠️ 姿勢が検出されませんでした\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return image_rgb, annotated_image\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 姿勢推定を実行\\n\",\n",
    "    \"if filename:\\n\",\n",
    "    \"    original_image, pose_image = detect_pose(filename)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if original_image is not None and pose_image is not None:\\n\",\n",
    "    \"        # 結果を表示\\n\",\n",
    "    \"        fig, axes = plt.subplots(1, 2, figsize=(12, 6))\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # 元の画像\\n\",\n",
    "    \"        axes[0].imshow(original_image)\\n\",\n",
    "    \"        axes[0].set_title('元の画像')\\n\",\n",
    "    \"        axes[0].axis('off')\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # 姿勢推定結果\\n\",\n",
    "    \"        axes[1].imshow(pose_image)\\n\",\n",
    "    \"        axes[1].set_title('姿勢推定結果')\\n\",\n",
    "    \"        axes[1].axis('off')\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        plt.tight_layout()\\n\",\n",
    "    \"        plt.show()\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"❌ 処理する画像がありません\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"section4-title\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. ランドマーク情報の表示\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"landmark-info\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def show_landmark_info(image_path):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    ランドマーク情報を詳細に表示する関数\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    image = cv2.imread(image_path)\\n\",\n",
    "    \"    if image is None:\\n\",\n",
    "    \"        return\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    with mp_pose.Pose(\\n\",\n",
    "    \"        static_image_mode=True,\\n\",\n",
    "    \"        model_complexity=2,\\n\",\n",
    "    \"        min_detection_confidence=0.5\\n\",\n",
    "    \"    ) as pose:\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        results = pose.process(image_rgb)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if results.pose_landmarks:\\n\",\n",
    "    \"            # 主要なランドマークの名前\\n\",\n",
    "    \"            landmark_names = [\\n\",\n",
    "    \"                \\\"鼻\\\", \\\"左目（内側）\\\", \\\"左目\\\", \\\"左目（外側）\\\", \\\"右目（内側）\\\",\\n\",\n",
    "    \"                \\\"右目\\\", \\\"右目（外側）\\\", \\\"左耳\\\", \\\"右耳\\\", \\\"左口角\\\",\\n\",\n",
    "    \"                \\\"右口角\\\", \\\"左肩\\\", \\\"右肩\\\", \\\"左肘\\\", \\\"右肘\\\",\\n\",\n",
    "    \"                \\\"左手首\\\", \\\"右手首\\\", \\\"左小指\\\", \\\"右小指\\\", \\\"左人差し指\\\",\\n\",\n",
    "    \"                \\\"右人差し指\\\", \\\"左親指\\\", \\\"右親指\\\", \\\"左腰\\\", \\\"右腰\\\",\\n\",\n",
    "    \"                \\\"左膝\\\", \\\"右膝\\\", \\\"左足首\\\", \\\"右足首\\\", \\\"左踵\\\",\\n\",\n",
    "    \"                \\\"右踵\\\", \\\"左足先\\\", \\\"右足先\\\"\\n\",\n",
    "    \"            ]\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            print(\\\"🔍 検出されたランドマーク情報:\\\")\\n\",\n",
    "    \"            print(\\\"=\" * 50)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            for i, (landmark, name) in enumerate(zip(results.pose_landmarks.landmark, landmark_names)):\\n\",\n",
    "    \"                print(f\\\"{i:2d}. {name:12}: x={landmark.x:.3f}, y={landmark.y:.3f}, z={landmark.z:.3f}, visibility={landmark.visibility:.3f}\\\")\\n\",\n",
    "    \"                \\n\",\n",
    "    \"                # 最初の10個だけ表示（表示を簡潔にするため）\\n\",\n",
    "    \"                if i >= 9:\\n\",\n",
    "    \"                    print(\\\"   ... (残りのランドマークは省略)\\\")\\n\",\n",
    "    \"                    break\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            print(\\\"❌ ランドマークが検出されませんでした\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ランドマーク情報を表示\\n\",\n",
    "    \"if filename:\\n\",\n",
    "    \"    show_landmark_info(filename)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"summary\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. まとめ\\n\",\n",
    "    \"\\n\",\n",
    "    \"### 🎯 このノートブックで学んだこと\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. **MediaPipe Pose の基本的な使い方**\\n\",\n",
    "    \"   - 簡単なセットアップと設定\\n\",\n",
    "    \"   - 画像からの姿勢推定\\n\",\n",
    "    \"\\n\",\n",
    "    \"2. **姿勢推定の結果**\\n\",\n",
    "    \"   - 33個のランドマークポイントの検出\\n\",\n",
    "    \"   - スケルトンの可視化\\n\",\n",
    "    \"   - 座標情報の取得\\n\",\n",
    "    \"\\n\",\n",
    "    \"3. **応用可能性**\\n\",\n",
    "    \"   - フィットネスアプリ\\n\",\n",
    "    \"   - 動作解析\\n\",\n",
    "    \"   - ゲーム制御\\n\",\n",
    "    \"   - 医療・リハビリ支援\\n\",\n",
    "    \"\\n\",\n",
    "    \"### 💡 次のステップ\\n\",\n",
    "    \"\\n\",\n",
    "    \"- Webカメラを使ったリアルタイム姿勢推定\\n\",\n",
    "    \"- 動画ファイルの姿勢推定\\n\",\n",
    "    \"- 特定の動作やポーズの判定\\n\",\n",
    "    \"- 複数人の姿勢推定\\n\",\n",
    "    \"\\n\",\n",
    "    \"---\\n\",\n",
    "    \"\\n\",\n",
    "    \"**🎉 MediaPipe Pose を使った姿勢推定が完了しました！**\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.5\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d013bb3",
   "metadata": {},
   "source": [
    "## 1. ライブラリのインストールとインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c4aa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なライブラリをインストール\n",
    "!pip install mediapipe opencv-python matplotlib\n",
    "\n",
    "print(\"✅ ライブラリのインストールが完了しました！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e001d7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# MediaPipe Pose の設定\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "print(\"✅ ライブラリのインポートが完了しました！\")\n",
    "print(f\"MediaPipe version: {mp.__version__}\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa9f864",
   "metadata": {},
   "source": [
    "## 2. 画像アップロード機能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bcc471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colabでのファイルアップロード機能\n",
    "try:\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    if uploaded:\n",
    "        # アップロードされたファイルの最初のものを使用\n",
    "        filename = list(uploaded.keys())[0]\n",
    "        print(f\"📁 アップロードされたファイル: {filename}\")\n",
    "    else:\n",
    "        print(\"ファイルがアップロードされませんでした\")\n",
    "        filename = None\n",
    "        \n",
    "except ImportError:\n",
    "    # Google Colab以外の環境の場合はサンプル画像のURLを使用\n",
    "    print(\"🌐 サンプル画像を使用します\")\n",
    "    import urllib.request\n",
    "    \n",
    "    # サンプル画像のダウンロード\n",
    "    sample_url = \"https://images.unsplash.com/photo-1571019613454-1cb2f99b2d8b?w=400\"\n",
    "    filename = \"sample_person.jpg\"\n",
    "    \n",
    "    try:\n",
    "        urllib.request.urlretrieve(sample_url, filename)\n",
    "        print(f\"📁 サンプル画像をダウンロードしました: {filename}\")\n",
    "    except:\n",
    "        print(\"❌ サンプル画像のダウンロードに失敗しました\")\n",
    "        filename = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc3d09c",
   "metadata": {},
   "source": [
    "## 3. 姿勢推定の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019d274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_pose(image_path):\n",
    "    \"\"\"\n",
    "    画像から姿勢を検出する関数\n",
    "    \"\"\"\n",
    "    # 画像を読み込み\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"❌ 画像を読み込めませんでした: {image_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    # BGR から RGB に変換\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # MediaPipe Pose で姿勢推定\n",
    "    with mp_pose.Pose(\n",
    "        static_image_mode=True,\n",
    "        model_complexity=2,\n",
    "        enable_segmentation=True,\n",
    "        min_detection_confidence=0.5\n",
    "    ) as pose:\n",
    "        \n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        # 結果を描画\n",
    "        annotated_image = image_rgb.copy()\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            # ランドマークとスケルトンを描画\n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image,\n",
    "                results.pose_landmarks,\n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()\n",
    "            )\n",
    "            \n",
    "            print(\"✅ 姿勢が検出されました！\")\n",
    "            print(f\"検出されたランドマーク数: {len(results.pose_landmarks.landmark)}\")\n",
    "        else:\n",
    "            print(\"⚠️ 姿勢が検出されませんでした\")\n",
    "    \n",
    "    return image_rgb, annotated_image\n",
    "\n",
    "# 姿勢推定を実行\n",
    "if filename:\n",
    "    original_image, pose_image = detect_pose(filename)\n",
    "    \n",
    "    if original_image is not None and pose_image is not None:\n",
    "        # 結果を表示\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        \n",
    "        # 元の画像\n",
    "        axes[0].imshow(original_image)\n",
    "        axes[0].set_title('元の画像')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # 姿勢推定結果\n",
    "        axes[1].imshow(pose_image)\n",
    "        axes[1].set_title('姿勢推定結果')\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"❌ 処理する画像がありません\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90b8e78",
   "metadata": {},
   "source": [
    "## 4. ランドマーク情報の表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e7e74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_landmark_info(image_path):\n",
    "    \"\"\"\n",
    "    ランドマーク情報を詳細に表示する関数\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        return\n",
    "    \n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    with mp_pose.Pose(\n",
    "        static_image_mode=True,\n",
    "        model_complexity=2,\n",
    "        min_detection_confidence=0.5\n",
    "    ) as pose:\n",
    "        \n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            # 主要なランドマークの名前\n",
    "            landmark_names = [\n",
    "                \"鼻\", \"左目（内側）\", \"左目\", \"左目（外側）\", \"右目（内側）\",\n",
    "                \"右目\", \"右目（外側）\", \"左耳\", \"右耳\", \"左口角\",\n",
    "                \"右口角\", \"左肩\", \"右肩\", \"左肘\", \"右肘\",\n",
    "                \"左手首\", \"右手首\", \"左小指\", \"右小指\", \"左人差し指\",\n",
    "                \"右人差し指\", \"左親指\", \"右親指\", \"左腰\", \"右腰\",\n",
    "                \"左膝\", \"右膝\", \"左足首\", \"右足首\", \"左踵\",\n",
    "                \"右踵\", \"左足先\", \"右足先\"\n",
    "            ]\n",
    "            \n",
    "            print(\"🔍 検出されたランドマーク情報:\")\n",
    "            print(\"=\" * 50)\n",
    "            \n",
    "            for i, (landmark, name) in enumerate(zip(results.pose_landmarks.landmark, landmark_names)):\n",
    "                print(f\"{i:2d}. {name:12}: x={landmark.x:.3f}, y={landmark.y:.3f}, z={landmark.z:.3f}, visibility={landmark.visibility:.3f}\")\n",
    "                \n",
    "                # 最初の10個だけ表示（表示を簡潔にするため）\n",
    "                if i >= 9:\n",
    "                    print(\"   ... (残りのランドマークは省略)\")\n",
    "                    break\n",
    "        else:\n",
    "            print(\"❌ ランドマークが検出されませんでした\")\n",
    "\n",
    "# ランドマーク情報を表示\n",
    "if filename:\n",
    "    show_landmark_info(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f9d815",
   "metadata": {},
   "source": [
    "## 5. まとめ\n",
    "\n",
    "### 🎯 このノートブックで学んだこと\n",
    "\n",
    "1. **MediaPipe Pose の基本的な使い方**\n",
    "   - 簡単なセットアップと設定\n",
    "   - 画像からの姿勢推定\n",
    "\n",
    "2. **姿勢推定の結果**\n",
    "   - 33個のランドマークポイントの検出\n",
    "   - スケルトンの可視化\n",
    "   - 座標情報の取得\n",
    "\n",
    "3. **応用可能性**\n",
    "   - フィットネスアプリ\n",
    "   - 動作解析\n",
    "   - ゲーム制御\n",
    "   - 医療・リハビリ支援\n",
    "\n",
    "### 💡 次のステップ\n",
    "\n",
    "- Webカメラを使ったリアルタイム姿勢推定\n",
    "- 動画ファイルの姿勢推定\n",
    "- 特定の動作やポーズの判定\n",
    "- 複数人の姿勢推定\n",
    "\n",
    "---\n",
    "\n",
    "**🎉 MediaPipe Pose を使った姿勢推定が完了しました！**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
